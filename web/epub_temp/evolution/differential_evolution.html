<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
  <head>
    <meta http-equiv="Content-Type" content="application/xhtml+xml; charset=utf-8" />
    <title>Clever Algorithms</title>
    <link rel="stylesheet" href="main.css" type="text/css" />
  </head>
  <body>
    
<a id='differential_evolution'><h1>Differential Evolution</h1></a>
<p>
<em>Differential Evolution, DE.</em>
</p>

<a id='taxonomy'><h2>Taxonomy</h2></a>
<p>
Differential Evolution is a Stochastic Direct Search and Global Optimization algorithm, and is an instance of an Evolutionary Algorithm from the field of Evolutionary Computation.
It is related to sibling Evolutionary Algorithms such as the Genetic Algorithm, Evolutionary Programming, and Evolution Strategies, and has some similarities with Particle Swarm Optimization.
</p>


<a id='strategy'><h2>Strategy</h2></a>
<p>
The Differential Evolution algorithm involves maintaining a population of candidate solutions subjected to iterations of recombination, evaluation, and selection. The recombination approach involves the creation of new candidate solution components based on the weighted difference between two randomly selected population members added to a third population member. This perturbs population members relative to the spread of the broader population. In conjunction with selection, the perturbation effect self-organizes the sampling of the problem space, bounding it to known areas of interest.
</p>


<a id='procedure'><h2>Procedure</h2></a>
<p>
Differential Evolution has a specialized nomenclature that describes the adopted configuration. This takes the form of DE/<em>x</em>/<em>y</em>/<em>z</em>, where <em>x</em> represents the solution to be perturbed (such a random or best). The <em>y</em> signifies the number of difference vectors used in the perturbation of <em>x</em>, where a difference vectors is the difference between two randomly selected although distinct members of the population. Finally, <em>z</em> signifies the recombination operator performed such as <code>bin</code> for binomial and <code>exp</code> for exponential.
</p>
<p>
Algorithm (below) provides a pseudocode listing of the Differential Evolution algorithm for minimizing a cost function, specifically a DE/rand/1/bin configuration. Algorithm (below) provides a pseudocode listing of the <code>NewSample</code> function from the Differential Evolution algorithm.
</p>
<div class='pseudocode'>
<strong><strong><code>Input</code></strong></strong>: 
$Population_{size}$, $Problem_{size}$, $Weighting_{factor}$, $Crossover_{rate}$
<br />
<strong><strong><code>Output</code></strong></strong>: 
$S_{best}$
<br />
<code>Population</code> $\leftarrow$ <code>InitializePopulation</code>($Population_{size}$, $Problem_{size}$)<br />
<code>EvaluatePopulation</code>(<code>Population</code>)<br />
$S_{best}$ $\leftarrow$ <code>GetBestSolution</code>(<code>Population</code>)<br />
<strong><code>While</code></strong> ( $\neg$ <code>StopCondition</code>())<br />
&nbsp;&nbsp;&nbsp;&nbsp;<code>NewPopulation</code> $\leftarrow \emptyset$<br />
&nbsp;&nbsp;&nbsp;&nbsp;<strong><code>For</code></strong> ($P_{i}$ $\in$ <code>Population</code>)<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$S_{i}$ $\leftarrow$ <code>NewSample</code>($P_{i}$, <code>Population</code>, $Problem_{size}$, $Weighting_{factor}$, $Crossover_{rate}$)<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong><code>If</code></strong> (<code>Cost</code>($S_{i}$) $\leq$ <code>Cost</code>($P_{i}$))<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>NewPopulation</code> $\leftarrow$ $S_{i}$<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong><code>Else</code></strong><br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>NewPopulation</code> $\leftarrow$ $P_{i}$<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong><code>End</code></strong><br />
&nbsp;&nbsp;&nbsp;&nbsp;<strong><code>End</code></strong><br />
&nbsp;&nbsp;&nbsp;&nbsp;<code>Population</code> $\leftarrow$ <code>NewPopulation</code><br />
&nbsp;&nbsp;&nbsp;&nbsp;<code>EvaluatePopulation</code>(<code>Population</code>)<br />
&nbsp;&nbsp;&nbsp;&nbsp;$S_{best}$ $\leftarrow$ <code>GetBestSolution</code>(<code>Population</code>)<br />
<strong><code>End</code></strong><br />
<strong><code>Return</code></strong> ($S_{best}$)<br />
</div>
<div class='caption'>Pseudocode for Differential Evolution.</div>

<div class='pseudocode'>
<strong><strong><code>Input</code></strong></strong>: 
$P_{0}$, <code>Population</code>, <code>NP</code>, <code>F</code>, <code>CR</code>
<br />
<strong><strong><code>Output</code></strong></strong>: 
$S$
<br />
<strong><code>Repeat</code></strong><br />
&nbsp;&nbsp;&nbsp;&nbsp;$P_{1}$ $\leftarrow$ <code>RandomMember</code>(<code>Population</code>)<br />
<strong><code>Until</code></strong> $P_{1}$ $\neq$ $P_{0}$
<br />
<strong><code>Repeat</code></strong><br />
&nbsp;&nbsp;&nbsp;&nbsp;$P_{2}$ $\leftarrow$ <code>RandomMember</code>(<code>Population</code>)<br />
<strong><code>Until</code></strong> $P_{2}$ $\neq$ $P_{0}$ $\vee$ $P_{2}$ $\neq$ $P_{1}$
<br />
<strong><code>Repeat</code></strong><br />
&nbsp;&nbsp;&nbsp;&nbsp;$P_{3}$ $\leftarrow$ <code>RandomMember</code>(<code>Population</code>)<br />
<strong><code>Until</code></strong> $P_{3}$ $\neq$ $P_{0}$ $\vee$ $P_{3}$ $\neq$ $P_{1}$ $\vee$ $P_{3}$ $\neq$ $P_{2}$
<br />
<code>CutPoint</code> $\leftarrow$ <code>RandomPosition</code>(<code>NP</code>)<br />
$S$ $\leftarrow0$<br />
<strong><code>For</code></strong> ($i$ <strong><code>To</code></strong> <code>NP</code>)<br />
&nbsp;&nbsp;&nbsp;&nbsp;<strong><code>If</code></strong> ($i \equiv$  <code>CutPoint</code> $\wedge$ <code>Rand</code>() &lt; <code>CR</code>)<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$S_{i}$ $\leftarrow$ $P_{3_i}$ + <code>F</code> $\times$ ($P_{1_i}$ - $P_{2_i}$)<br />
&nbsp;&nbsp;&nbsp;&nbsp;<strong><code>Else</code></strong><br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$S_{i}$ $\leftarrow$ $P_{0_i}$<br />
&nbsp;&nbsp;&nbsp;&nbsp;<strong><code>End</code></strong><br />
<strong><code>End</code></strong><br />
<strong><code>Return</code></strong> ($S$)<br />
</div>
<div class='caption'>Pseudocode for the <code>NewSample</code> function.</div>



<a id='heuristics'><h2>Heuristics</h2></a>
<ul>
<li> Differential evolution was designed for nonlinear, non-differentiable continuous function optimization.</li>
<li> The weighting factor $F \in [0,2]$ controls the amplification of differential variation, a value of 0.8 is suggested.</li>
<li> the crossover weight $CR \in [0,1]$ probabilistically controls the amount of recombination, a value of 0.9 is suggested.</li>
<li> The initial population of candidate solutions should be randomly generated from within the space of valid solutions.</li>
<li> The popular configurations are DE/rand/1/* and DE/best/2/*.</li>
</ul>


<a id='code_listing'><h2>Code Listing</h2></a>
<p>
Listing (below) provides an example of the Differential Evolution algorithm implemented in the Ruby Programming Language.
The demonstration problem is an instance of a continuous function optimization that seeks $\min f(x)$ where $f=\sum_{i=1}^n x_{i}^2$, $-5.0\leq x_i \leq 5.0$ and $n=3$. The optimal solution for this basin function is $(v_0,\ldots,v_{n-1})=0.0$.
The algorithm is an implementation of Differential Evolution with the DE/rand/1/bin configuration proposed by Storn and Price  [<a href='#Storn1997'>Storn1997</a>]. <br />
</p>
<pre class='prettyprint lang-rb'>
def objective_function(vector)
  return vector.inject(0.0) {|sum, x| sum +  (x ** 2.0)}
end

def random_vector(minmax)
  return Array.new(minmax.size) do |i|
    minmax[i][0] + ((minmax[i][1] - minmax[i][0]) * rand())
  end
end

def de_rand_1_bin(p0, p1, p2, p3, f, cr, search_space)
  sample = {:vector=&gt;Array.new(p0[:vector].size)}
  cut = rand(sample[:vector].size-1) + 1
  sample[:vector].each_index do |i|
    sample[:vector][i] = p0[:vector][i]
    if (i==cut or rand() &lt; cr)
      v = p3[:vector][i] + f * (p1[:vector][i] - p2[:vector][i])
      v = search_space[i][0] if v &lt; search_space[i][0]
      v = search_space[i][1] if v &gt; search_space[i][1]
      sample[:vector][i] = v
    end
  end
  return sample
end

def select_parents(pop, current)
  p1, p2, p3 = rand(pop.size), rand(pop.size), rand(pop.size)
  p1 = rand(pop.size) until p1 != current
  p2 = rand(pop.size) until p2 != current and p2 != p1
  p3 = rand(pop.size) until p3 != current and p3 != p1 and p3 != p2
  return [p1,p2,p3]
end

def create_children(pop, minmax, f, cr)
  children = []
  pop.each_with_index do |p0, i|
    p1, p2, p3 = select_parents(pop, i)
    children &lt;&lt; de_rand_1_bin(p0, pop[p1], pop[p2], pop[p3], f, cr, minmax)
  end
  return children
end

def select_population(parents, children)
  return Array.new(parents.size) do |i|
    (children[i][:cost]&lt;=parents[i][:cost]) ? children[i] : parents[i]
  end
end

def search(max_gens, search_space, pop_size, f, cr)
  pop = Array.new(pop_size) {|i| {:vector=&gt;random_vector(search_space)}}
  pop.each{|c| c[:cost] = objective_function(c[:vector])}
  best = pop.sort{|x,y| x[:cost] &lt;=&gt; y[:cost]}.first
  max_gens.times do |gen|
    children = create_children(pop, search_space, f, cr)
    children.each{|c| c[:cost] = objective_function(c[:vector])}
    pop = select_population(pop, children)
    pop.sort!{|x,y| x[:cost] &lt;=&gt; y[:cost]}
    best = pop.first if pop.first[:cost] &lt; best[:cost]
    puts " &gt; gen #{gen+1}, fitness=#{best[:cost]}"
  end
  return best
end

if __FILE__ == $0
  # problem configuration
  problem_size = 3
  search_space = Array.new(problem_size) {|i| [-5, +5]}
  # algorithm configuration
  max_gens = 200
  pop_size = 10*problem_size
  weightf = 0.8
  crossf = 0.9
  # execute the algorithm
  best = search(max_gens, search_space, pop_size, weightf, crossf)
  puts "done! Solution: f=#{best[:cost]}, s=#{best[:vector].inspect}"
end
</pre>
<div class='download_src'><a href='differential_evolution.rb'>Download Source</a></div>
<div class='caption'>Differential Evolution in Ruby</div>


<a id='references'><h2>References</h2></a>

<a id='primary_sources'><h3>Primary Sources</h3></a>
<p>
The Differential Evolution algorithm was presented by Storn and Price in a technical report that considered DE1 and DE2 variants of the approach applied to a suite of continuous function optimization problems  [<a href='#Storn1995'>Storn1995</a>].
An early paper by Storn applied the approach to the optimization of an IIR-filter (Infinite Impulse Response)  [<a href='#Storn1996a'>Storn1996a</a>]. A second early paper applied the approach to a second suite of benchmark problem instances, adopting the contemporary nomenclature for describing the approach, including the DE/rand/1/* and DE/best/2/* variations  [<a href='#Storn1996b'>Storn1996b</a>].
The early work including technical reports and conference papers by Storn and Price culminated in a seminal journal article  [<a href='#Storn1997'>Storn1997</a>].
</p>


<a id='learn_more'><h3>Learn More</h3></a>
<p>
A classical overview of Differential Evolution was presented by Price and Storn  [<a href='#Price1997'>Price1997</a>], and terse introduction to the approach for function optimization is presented by Storn  [<a href='#Storn1996'>Storn1996</a>]. A seminal extended description of the algorithm with sample applications was presented by Storn and Price as a book chapter  [<a href='#Price1999'>Price1999</a>].
Price, Storn, and Lampinen released a contemporary book dedicated to Differential Evolution including theory, benchmarks, sample code, and numerous application demonstrations  [<a href='#Price2005'>Price2005</a>]. Chakraborty also released a book considering extensions to address complexities such as rotation invariance and stopping criteria   [<a href='#Chakraborty2008'>Chakraborty2008</a>].
</p>




<h2>Bibliography</h2>
<table>
 <tr valign="top">
 <td><a id='Chakraborty2008'>[Chakraborty2008]</a></td>
 <td>U. K. Chakraborty, "<a href="http://scholar.google.com.au/scholar?q=Advances+in+Differential+Evolution">Advances in Differential Evolution</a>", Springer, 2008.</td>
 </tr>
 <tr valign="top">
 <td><a id='Price1997'>[Price1997]</a></td>
 <td>K. Price and R. Storn, "<a href="http://scholar.google.com.au/scholar?q=Differential+Evolution:+Numerical+Optimization+Made+Easy">Differential Evolution: Numerical Optimization Made Easy</a>", Dr. Dobb's Journal, 1997.</td>
 </tr>
 <tr valign="top">
 <td><a id='Price1999'>[Price1999]</a></td>
 <td>K. V. Price, "<a href="http://scholar.google.com.au/scholar?q=An+introduction+to+differential+evolution">An introduction to differential evolution</a>", in New Ideas in Optimization, pages 79&ndash;108, McGraw-Hill Ltd., UK, 1999.</td>
 </tr>
 <tr valign="top">
 <td><a id='Price2005'>[Price2005]</a></td>
 <td>K. V. Price and R. M. Storn and J. A. Lampinen, "<a href="http://scholar.google.com.au/scholar?q=Differential+evolution:+A+practical+approach+to+global+optimization">Differential evolution: A practical approach to global optimization</a>", Springer, 2005.</td>
 </tr>
 <tr valign="top">
 <td><a id='Storn1995'>[Storn1995]</a></td>
 <td>R. Storn and K. Price, "<a href="http://scholar.google.com.au/scholar?q=Differential+Evolution:+A+Simple+and+Efficient+Adaptive+Scheme+for++Global+Optimization+over+Continuous+Spaces">Differential Evolution: A Simple and Efficient Adaptive Scheme for 	Global Optimization over Continuous Spaces</a>", Technical Report TR-95-012, International Computer Science Institute, Berkeley, CA, 1995.</td>
 </tr>
 <tr valign="top">
 <td><a id='Storn1996'>[Storn1996]</a></td>
 <td>R. Storn, "<a href="http://scholar.google.com.au/scholar?q=On+the+Usage+of+Differential+Evolution+for+Function+Optimization">On the Usage of Differential Evolution for Function Optimization</a>", in Proceedings Fuzzy Information Processing Society, 1996 Biennial Conference 	of the North American, 1996.</td>
 </tr>
 <tr valign="top">
 <td><a id='Storn1996a'>[Storn1996a]</a></td>
 <td>R. Storn, "<a href="http://scholar.google.com.au/scholar?q=Differential+evolution+design+of+an+IIR-filter">Differential evolution design of an IIR-filter</a>", in Proceedings IEEE Conference Evolutionary Computation, 1996.</td>
 </tr>
 <tr valign="top">
 <td><a id='Storn1996b'>[Storn1996b]</a></td>
 <td>R. Storn and K. Price, "<a href="http://scholar.google.com.au/scholar?q=Minimizing+the+real+functions+of+the+ICEC'96+contest+by+differential++evolution">Minimizing the real functions of the ICEC'96 contest by differential 	evolution</a>", in Proceedings of IEEE International Conference on Evolutionary Computation, 1996.</td>
 </tr>
 <tr valign="top">
 <td><a id='Storn1997'>[Storn1997]</a></td>
 <td>R. Storn and K. Price, "<a href="http://scholar.google.com.au/scholar?q=Differential+evolution:+A+simple+and+efficient+heuristic+for+global++optimization+over+continuous+spaces">Differential evolution: A simple and efficient heuristic for global 	optimization over continuous spaces</a>", Journal of Global Optimization, 1997.</td>
 </tr>
</table>


  </body>
</html>  
