% The Clever Algorithms Project: http://www.CleverAlgorithms.com
% (c) Copyright 2010 Jason Brownlee. Some Rights Reserved. 
% This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 2.5 Australia License.

% This is an algorithm description, see:
% Jason Brownlee. A Template for Standardized Algorithm Descriptions. Technical Report CA-TR-20100107-1, The Clever Algorithms Project http://www.CleverAlgorithms.com, January 2010.

% Name
% The algorithm name defines the canonical name used to refer to the technique, in addition to common aliases, abbreviations, and acronyms. The name is used in terms of the heading and sub-headings of an algorithm description.
\section{Learning Classifier System} 
\label{sec:learning_classifier_system}
\index{Learning Classifier System}

% other names
% What is the canonical name and common aliases for a technique?
% What are the common abbreviations and acronyms for a technique?
\emph{Learning Classifier System, LCS.}

% Taxonomy: Lineage and locality
% The algorithm taxonomy defines where a techniques fits into the field, both the specific subfields of Computational Intelligence and Biologically Inspired Computation as well as the broader field of Artificial Intelligence. The taxonomy also provides a context for determining the relation- ships between algorithms. The taxonomy may be described in terms of a series of relationship statements or pictorially as a venn diagram or a graph with hierarchical structure.
\subsection{Taxonomy}
% To what fields of study does a technique belong?
The Learning Classifier System algorithm is both an instance of an Evolutionary Algorithm from the field of Evolutionary Computation and an instance of a Reinforcement Learning algorithm from Machine Learning. Internally, Learning Classifier Systems make use of a Genetic Algorithm (Section~\ref{sec:genetic_algorithm}).
% What are the closely related approaches to a technique?
The Learning Classifier System is a theoretical system with a number of implementations. The two main approaches to implementing and investigating the system empirically are the Pittsburgh-style that seeks to optimize the whole classifier, and the Michigan-style that optimize responsive rulesets. 
% common 
The Michigan-style Learning Classifier is the most common and is comprised of two versions: the ZCS (zeroth-level classifier system) and the XCS (accuracy-based classifier system).

% Strategy: Problem solving plan
% The strategy is an abstract description of the computational model. The strategy describes the information processing actions a technique shall take in order to achieve an objective. The strategy provides a logical separation between a computational realization (procedure) and a analogous system (metaphor). A given problem solving strategy may be realized as one of a number specific algorithms or problem solving systems. The strategy description is textual using information processing and algorithmic terminology.
\subsection{Strategy}
% What is the information processing objective of a technique?
The objective of the Learning Classifier System algorithm is to optimize payoff based on exposure to stimuli from a problem-specific environment.
% What is a techniques plan of action?
This is achieved by managing credit assignment for those rules that prove useful and searching for new rules and new variations on existing rules using an evolutionary process.

% Procedure: Abstract computation
% The algorithmic procedure summarizes the specifics of realizing a strategy as a systemized and parameterized computation. It outlines how the algorithm is organized in terms of the data structures and representations. The procedure may be described in terms of software engineering and computer science artifacts such as Pseudocode, design diagrams, and relevant mathematical equations.
\subsection{Procedure}
% What are the data structures and representations used in a technique?
% actors
The actors of the system include detectors, messages, effectors, feedback, and classifiers. Detectors are used by the system to perceive the state of the environment. Messages are the discrete information packets passed from the detectors into the system. The system performs information processing on messages, and messages may directly result in actions in the environment. Effectors control the actions of the system on and within the environment. In addition to the system actively perceiving via its detections, it may also receive directed feedback from the environment (payoff). Classifiers are condition-action rules that provide a filter for messages. If a message satisfies the conditional part of the classifier, the action of the classifier triggers. Rules act as message processors.
% data
Message a fixed length bitstring. A classifier is defined as a ternary string with an alphabet $\in \{1, 0, \#\}$, where the $\#$ represents do not care (matching either 1 or 0). 

% What is the computational recipe for a technique?
The processing loop for the Learning Classifier system is as follows:

\begin{enumerate}
	\item Messages from the environment are placed on the message list.
	\item The conditions of each classifier are checked to see if they are satisfied by at least one message in the message list.
	\item All classifiers that are satisfied participate in a competition, those that win post their action to the message list.
	\item All messages directed to the effectors are executed (causing actions in the environment).
	\item  All messages on the message list from the previous cycle are deleted (messages persist for a single cycle).
\end{enumerate}

% algorithm
The algorithm may be described in terms of the main processing loop and two sub-algorithms: a reinforcement learning algorithm such as the bucket brigade algorithm or Q-learning, and a genetic algorithm for optimization of the system.
% presentated
Algorithm~\ref{alg:learning_classifier_system} provides a pseudocode listing of the high-level processing loop of the Learning Classifier System, specifically the XCS as described by Butz and Wilson \cite{Butz2002a}. 

\begin{algorithm}[h!t]
	\SetLine  

	% data
	\SetKwData{Population}{Population}
	\SetKwData{Environment}{env}
	\SetKwData{EnvironmentDetails}{EnvironmentDetails}
	\SetKwData{Input}{$Input_{t}$}
	\SetKwData{Matchset}{Matchset}
	\SetKwData{Prediction}{Prediction}
	\SetKwData{Action}{Action}
	\SetKwData{Actionset}{$ActionSet_{t}$}
	\SetKwData{Reward}{$Reward_{t}$}
	\SetKwData{Payoff}{$Payoff_{t}$}
	\SetKwData{LastActionset}{$ActionSet_{t-1}$}
	\SetKwData{LastInput}{$Input_{t-1}$}
	\SetKwData{LastReward}{$Reward_{t-1}$}

	% functions
	\SetKwFunction{StopCondition}{StopCondition}
	\SetKwFunction{InitializeEnvironment}{InitializeEnvironment}
	\SetKwFunction{InitializePopulation}{InitializePopulation}
	\SetKwFunction{GenerateMatchSet}{GenerateMatchSet}
	\SetKwFunction{GeneratePrediction}{GeneratePrediction}
	\SetKwFunction{SelectionAction}{SelectionAction}
	\SetKwFunction{GenerateActionSet}{GenerateActionSet}
	\SetKwFunction{ExecuteAction}{ExecuteAction}
	\SetKwFunction{CalculatePayoff}{CalculatePayoff}
	\SetKwFunction{PerformLearning}{PerformLearning}
	\SetKwFunction{RunGeneticAlgorithm}{RunGeneticAlgorithm}
	\SetKwFunction{LastStepOfTask}{LastStepOfTask}
  
	% I/O
	\KwIn{\EnvironmentDetails}		
	\KwOut{\Population}
  	% Algorithm
	
	\Environment $\leftarrow$ \InitializeEnvironment{\EnvironmentDetails}\;
	\Population $\leftarrow$ \InitializePopulation{}\;
	\LastActionset $\leftarrow$ $\emptyset$\;
	\LastInput $\leftarrow$ $\emptyset$\;
	\LastReward $\leftarrow$ $\emptyset$\;
		
	\While{$\neg$\StopCondition{}}{
		\Input $\leftarrow$ \Environment\;
		\Matchset $\leftarrow$ \GenerateMatchSet{\Population, \Input}\;
		\Prediction $\leftarrow$ \GeneratePrediction{\Matchset}\;
		\Action $\leftarrow$ \SelectionAction{\Prediction}\;
		\Actionset $\leftarrow$ \GenerateActionSet{\Action, \Matchset}\;
		\Reward $\leftarrow$ \ExecuteAction{\Action, \Environment}\;
		\If{\LastActionset $\neq$ $\emptyset$}{
			\Payoff $\leftarrow$ \CalculatePayoff{\LastReward, \Prediction}\;
			\PerformLearning{\LastActionset, \Payoff, \Population}\;
			\RunGeneticAlgorithm{\LastActionset, \LastInput, \Population}\;
		}
		
		\eIf{\LastStepOfTask{\Environment, \Action}}{
			\Payoff $\leftarrow$ \Reward\;
			\PerformLearning{\Actionset, \Payoff, \Population}\;
			\RunGeneticAlgorithm{\Actionset, \Input, \Population}\;
			\LastActionset $\leftarrow$ $\emptyset$\;
		}{
			\LastActionset $\leftarrow$ \Actionset\;
			\LastInput $\leftarrow$ \Input\;
			\LastReward $\leftarrow$ \Reward\;
		}
	}
	% end
	\caption{Pseudocode for the LCS.}
	\label{alg:learning_classifier_system}
\end{algorithm}


% Heuristics: Usage guidelines
% The heuristics element describe the commonsense, best practice, and demonstrated rules for applying and configuring a parameterized algorithm. The heuristics relate to the technical details of the techniques procedure and data structures for general classes of application (neither specific implementations not specific problem instances). The heuristics are described textually, such as a series of guidelines in a bullet-point structure.
\subsection{Heuristics}
% What are the suggested configurations for a technique?
% What are the guidelines for the application of a technique to a problem instance?
The majority of the heuristics in this section are specific to the XCS Learning Classifier System as described by Butz and Wilson \cite{Butz2002a}.

\begin{itemize}
	\item Learning Classifier Systems are suited for problems with the following characteristics: perpetually novel events with significant noise, continual real-time requirements for action, implicitly or inexactly defined goals, and sparse payoff or reinforcement obtainable only through long sequences of tasks.
	\item The learning rate $\beta$ for a classifier's expected payoff, error, and fitness are typically in the range $[0.1,0.2]$.
	\item The frequency of running the genetic algorithm $\theta_{GA}$ should be in the range $[25,50]$.
	\item The discount factor used in multi-step programs $\gamma$ are typically in the around $0.71$.
	\item The minimum error whereby classifiers are considered to have equal accuracy $\epsilon_{0}$ is typically 10\% of the maximum reward.
	\item The probability of crossover in the genetic algorithm $\chi$ is typically in the range $[0.5,1.0]$.
	\item The probability of mutating a single position in a classifier in the genetic algorithm $\mu$ is typically in the range $[0.01,0.05]$.
	\item The experience threshold during classifier deletion $\theta_{del}$ is typically about 20.
	\item The experience threshold for a classifier during subsumption $\theta_{sub}$ is typically around 20.
	\item The initial values for a classifier's expected payoff $p_1$, error $\epsilon_1$, and fitness $f_1$ are typically small and close to zero.
	\item The probability of selecting a random action for the purposes of exploration $p_{exp}$ is typically close to 0.5.
	\item The minimum number of different actions that must be specified in a match set $\theta_{mna}$ is usually the total number of possible actions in the environment for the input.
	\item Subsumption should be used on problem domains that are known contain well defined rules for mapping inputs to outputs.
\end{itemize}

% The code description provides a minimal but functional version of the technique implemented with a programming language. The code description must be able to be typed into an appropriate computer, compiled or interpreted as need be, and provide a working execution of the technique. The technique implementation also includes a minimal problem instance to which it is applied, and both the problem and algorithm implementations are complete enough to demonstrate the techniques procedure. The description is presented as a programming source code listing.
\subsection{Code Listing}
% How is a technique implemented as an executable program?
% How is a technique applied to a concrete problem instance?
Listing~\ref{learning_classifier_system} provides an example of the Learning Classifier System algorithm implemented in the Ruby Programming Language. 
% problem
The problem is an instance of a Boolean multiplexer called the 6-multiplexer. It can be described as a classification problem, where each of the $2^6$ patterns of bits is associated with a boolean class $\in \{1,0\}$. For this problem instance, the first two bits may be decoded as an address into the remaining four bits that specify the class (for example in 100011, `10' decode to the index of `2' in the remaining 4 bits making the class `1'). In propositional logic this problem instance may be described as $F=(\neg x_0) (\neg x_1) x_2 + (\neg x_0) x_1 x_3 + x_0 (\neg x_1) x_4 + x_0 x_1 x_5$. 
% algorithm
The algorithm is an instance of XCS based on the description provided by Butz and Wilson \cite{Butz2002a} with the parameters based on the application of XCS to Boolean multiplexer problems by Wilson \cite{Wilson1995, Wilson1998}.
% specifics
The population is grown as needed, and subsumption which would be appropriate for the Boolean multiplexer problem was not used for brevity. The multiplexer problem is a single step problem, so the complexities of delayed payoff are not required. A number of parameters were hard coded to recommended values, specifically: $\alpha=0.1$, $v=-0.5$, $\delta=0.1$ and $P_{\#}=\frac{1}{3}$.

% the listing
\lstinputlisting[firstline=7,language=ruby,caption=Learning Classifier System in Ruby, label=learning_classifier_system]{../src/algorithms/evolutionary/learning_classifier_system.rb}


% References: Deeper understanding
% The references element description includes a listing of both primary sources of information about the technique as well as useful introductory sources for novices to gain a deeper understanding of the theory and application of the technique. The description consists of hand-selected reference material including books, peer reviewed conference papers, journal articles, and potentially websites. A bullet-pointed structure is suggested.
\subsection{References}
% What are the primary sources for a technique?
% What are the suggested reference sources for learning more about a technique?

% 
% Primary Sources
% 
\subsubsection{Primary Sources}
% seminal
Early ideas on the theory of Learning Classifier Systems were proposed by Holland \cite{Holland1976, Holland1977}, culminating in a standardized presentation a few years later \cite{Holland1980}.
% taxonomy
A number of implementations of the theoretical system were investigated, although a taxonomy of the two main streams was proposed by De Jong \cite{Jong1988}: 1) Pittsburgh-style proposed by Smith \cite{Smith1980, Smith1983} and 2) Holland-style or Michigan-style Learning classifiers that are further comprised of the Zeroth-level classifier (ZCS) \cite{Wilson1994} and the accuracy-based classifier (XCS) \cite{Wilson1995}.

% 
% Learn More
% 
\subsubsection{Learn More}
% classical
Booker, Goldberg, and Holland provide a classical introduction to Learning Classifier Systems including an overview of the state of the field and the algorithm in detail \cite{Booker1989}. Wilson and Goldberg also provide an introduction and review of the approach, taking a more critical stance \cite{Wilson1989}.
% review
Holmes et al.\ provide a contemporary review of the field focusing both on a description of the method and application areas to which the approach has been demonstrated successfully \cite{Holmes2002}.
% books
Lanzi, Stolzmann, and Wilson provide a seminal book in the field as a collection of papers covering the basics, advanced topics, and demonstration applications; a particular highlight from this book is the first section that provides a concise description of Learning Classifier Systems by many leaders and major contributors to the field \cite{Holland2000}, providing rare insight. 
Another paper from Lanzi and Riolo's book provides a detailed review of the development of the approach as it matured throughout the 1990s \cite{Lanzi2000a}.
% other book
Bull and Kovacs provide a second book introductory book to the field focusing on the theory of the approach and its practical application \cite{Bull2005}.


