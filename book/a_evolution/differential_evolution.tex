% The Clever Algorithms Project: http://www.CleverAlgorithms.com
% (c) Copyright 2010 Jason Brownlee. Some Rights Reserved. 
% This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 2.5 Australia License.

% This is an algorithm description, see:
% Jason Brownlee. A Template for Standardized Algorithm Descriptions. Technical Report CA-TR-20100107-1, The Clever Algorithms Project http://www.CleverAlgorithms.com, January 2010.

% Name
% The algorithm name defines the canonical name used to refer to the technique, in addition to common aliases, abbreviations, and acronyms. The name is used in terms of the heading and sub-headings of an algorithm description.
\section{Differential Evolution} 
\label{sec:differential_evolution}
\index{Differential Evolution}

% other names
% What is the canonical name and common aliases for a technique?
% What are the common abbreviations and acronyms for a technique?
\emph{Differential Evolution, DE.}

% Taxonomy: Lineage and locality
% The algorithm taxonomy defines where a techniques fits into the field, both the specific subfields of Computational Intelligence and Biologically Inspired Computation as well as the broader field of Artificial Intelligence. The taxonomy also provides a context for determining the relation- ships between algorithms. The taxonomy may be described in terms of a series of relationship statements or pictorially as a venn diagram or a graph with hierarchical structure.
\subsection{Taxonomy}
% To what fields of study does a technique belong?
Differential Evolution is a Stochastic Direct Search and Global Optimization algorithm, and is an instance of an Evolutionary Algorithm from the field of Evolutionary Computation.
% What are the closely related approaches to a technique?
It is related to sibling Evolutionary Algorithms such as the Genetic Algorithm (Section~\ref{sec:genetic_algorithm}), Evolutionary Programming (Section~\ref{sec:evolutionary_programming}), and Evolution Strategies (Section~\ref{sec:evolution_strategies}), and has some similarities with Particle Swarm Optimization (Section~\ref{sec:pso}).

% Strategy: Problem solving plan
% The strategy is an abstract description of the computational model. The strategy describes the information processing actions a technique shall take in order to achieve an objective. The strategy provides a logical separation between a computational realization (procedure) and a analogous system (metaphor). A given problem solving strategy may be realized as one of a number specific algorithms or problem solving systems. The strategy description is textual using information processing and algorithmic terminology.
\subsection{Strategy}
% What is the information processing objective of a technique?
% What is a techniques plan of action?
The Differential Evolution algorithm involves maintaining a population of candidate solutions subjected to iterations of recombination, evaluation, and selection. The recombination approach involves the creation of new candidate solution components based on the weighted difference between two randomly selected population members added to a third population member. This perturbs population members relative to the spread of the broader population. In conjunction with selection, the perturbation effect self-organizes the sampling of the problem space, bounding it to known areas of interest.

% Procedure: Abstract computation
% The algorithmic procedure summarizes the specifics of realizing a strategy as a systemized and parameterized computation. It outlines how the algorithm is organized in terms of the data structures and representations. The procedure may be described in terms of software engineering and computer science artifacts such as pseudo code, design diagrams, and relevant mathematical equations.
\subsection{Procedure}
% What are the data structures and representations used in a technique?
Differential Evolution has a specialized nomenclature that describes the adopted configuration. This takes the form of DE/\emph{x}/\emph{y}/\emph{z}, where \emph{x} represents the solution to be perturbed (such a random or best). The \emph{y} signifies the number of difference vectors used in the perturbation of \emph{x}, where a difference vectors is the difference between two randomly selected although distinct members of the population. Finally, \emph{z} signifies the recombination operator performed such as \texttt{bin} for binomial and \texttt{exp} for exponential. 

% What is the computational recipe for a technique?
Algorithm~\ref{alg:differential_evolution} provides a pseudocode listing of the Differential Evolution algorithm for minimizing a cost function, specifically a DE/\-rand/\-1/\-bin configuration. Algorithm~\ref{alg:new_sample} provides a pseudocode listing of the \texttt{NewSample} function from the Differential Evolution algorithm.

\begin{algorithm}[ht]
	\SetLine  

	% data
	\SetKwData{Best}{$S_{best}$}
	\SetKwData{Member}{$P_{i}$}
	\SetKwData{Sample}{$S_{i}$}
	\SetKwData{Population}{Population}
	\SetKwData{NewPopulation}{NewPopulation}	
	\SetKwData{PopulationSize}{$Population_{size}$}
	\SetKwData{NumParameters}{$Problem_{size}$}
	\SetKwData{WeightingFactor}{$Weighting_{factor}$}
	\SetKwData{CrossoverRate}{$Crossover_{rate}$}
	
	% functions
	\SetKwFunction{StopCondition}{StopCondition}
	\SetKwFunction{InitializePopulation}{InitializePopulation}
	\SetKwFunction{EvaluateCost}{EvaluatePopulation}
	\SetKwFunction{GetBestSolution}{GetBestSolution}
	\SetKwFunction{NewSample}{NewSample}
	\SetKwFunction{Cost}{Cost}
  
	% I/O
	\KwIn{\PopulationSize, \NumParameters, \WeightingFactor, \CrossoverRate}		
	\KwOut{\Best}
  	% Algorithm
	% initialize	
	\Population $\leftarrow$ \InitializePopulation{\PopulationSize, \NumParameters}\;
	% evaluate
	\EvaluateCost{\Population}\;
	% best
	\Best $\leftarrow$ \GetBestSolution{\Population}\;
	% loop
	\While{ $\neg$ \StopCondition{}} {
		\NewPopulation $\leftarrow \emptyset$\;
		% create new 
		\ForEach{\Member $\in$ \Population}{
			\Sample $\leftarrow$ \NewSample{\Member, \Population, \NumParameters, \WeightingFactor, \CrossoverRate}\;
			\eIf{\Cost{\Sample} $\leq$ \Cost{\Member}}{
				\NewPopulation $\leftarrow$ \Sample\;
			}{
				\NewPopulation $\leftarrow$ \Member\;
			}
		}
		\Population $\leftarrow$ \NewPopulation\;
		% eval
		\EvaluateCost{\Population}\;
		\Best $\leftarrow$ \GetBestSolution{\Population}\;
	}
	\Return{\Best}\;
	% end
	\caption{Pseudocode for Differential Evolution.}
	\label{alg:differential_evolution}
\end{algorithm}


\begin{algorithm}[ht]
	\SetLine  

	% data
	\SetKwData{Membera}{$P_{0}$}
	\SetKwData{Memberb}{$P_{1}$}
	\SetKwData{Memberc}{$P_{2}$}
	\SetKwData{Memberd}{$P_{3}$}
	\SetKwData{Memberai}{$P_{0_i}$}
	\SetKwData{Memberbi}{$P_{1_i}$}
	\SetKwData{Memberci}{$P_{2_i}$}
	\SetKwData{Memberdi}{$P_{3_i}$}
	\SetKwData{Sample}{$S$}
	\SetKwData{SampleVar}{$S_{i}$}
	\SetKwData{Population}{Population}
	\SetKwData{NumParameters}{NP}
	\SetKwData{WeightingFactor}{F}
	\SetKwData{CrossoverRate}{CR}
	\SetKwData{CutPoint}{CutPoint}
	
	% functions
	\SetKwFunction{RandomMemeber}{RandomMember}
	\SetKwFunction{RandomPosition}{RandomPosition}
	\SetKwFunction{Rand}{Rand}
  
	% I/O
	\KwIn{\Membera, \Population, \NumParameters, \WeightingFactor, \CrossoverRate}		
	\KwOut{\Sample}
	% Algorithm
	\Repeat{\Memberb $\neq$ \Membera}{\Memberb $\leftarrow$ \RandomMemeber{\Population}\;}
	\Repeat{\Memberc $\neq$ \Membera $\vee$ \Memberc $\neq$ \Memberb}{\Memberc $\leftarrow$ \RandomMemeber{\Population}\;}
	\Repeat{\Memberd $\neq$ \Membera $\vee$ \Memberd $\neq$ \Memberb $\vee$ \Memberd $\neq$ \Memberc}{\Memberd $\leftarrow$ \RandomMemeber{\Population}\;}
	\CutPoint $\leftarrow$ \RandomPosition{\NumParameters}\;
	\Sample $\leftarrow0$\;
	\For{$i$ $\KwTo$ \NumParameters}{
		\eIf{$i \equiv$  \CutPoint $\wedge$ \Rand{} $<$ \CrossoverRate}{
			\SampleVar $\leftarrow$ \Memberdi + \WeightingFactor $\times$ (\Memberbi - \Memberci)\;
		}{
			\SampleVar $\leftarrow$ \Memberai\;
		}
	}
	
	\Return{\Sample}\;
	% end
	\caption{Pseudocode for the \texttt{NewSample} function.}
	\label{alg:new_sample}
\end{algorithm}

% Heuristics: Usage guidelines
% The heuristics element describe the commonsense, best practice, and demonstrated rules for applying and configuring a parameterized algorithm. The heuristics relate to the technical details of the techniques procedure and data structures for general classes of application (neither specific implementations not specific problem instances). The heuristics are described textually, such as a series of guidelines in a bullet-point structure.
\subsection{Heuristics}
% What are the suggested configurations for a technique?
% What are the guidelines for the application of a technique to a problem instance?
\begin{itemize}
	\item Differential evolution was designed for nonlinear, non-differentiable continuous function optimization.
	\item The weighting factor $F \in [0,2]$ controls the amplification of differential variation, a value of 0.8 is suggested.
	\item the crossover weight $CR \in [0,1]$ probabilistically controls the amount of recombination, a value of 0.9 is suggested.
	\item The initial population of candidate solutions should be randomly generated from within the space of valid solutions.
	\item The popular configurations are DE/rand/1/* and DE/best/2/*. 
\end{itemize}

% The code description provides a minimal but functional version of the technique implemented with a programming language. The code description must be able to be typed into an appropriate computer, compiled or interpreted as need be, and provide a working execution of the technique. The technique implementation also includes a minimal problem instance to which it is applied, and both the problem and algorithm implementations are complete enough to demonstrate the techniques procedure. The description is presented as a programming source code listing.
\subsection{Code Listing}
% How is a technique implemented as an executable program?
% How is a technique applied to a concrete problem instance?
Listing~\ref{differential_evolution} provides an example of the Differential Evolution algorithm implemented in the Ruby Programming Language.
% problem
The demonstration problem is an instance of a continuous function optimization that seeks $\min f(x)$ where $f=\sum_{i=1}^n x_{i}^2$, $-5.0\leq x_i \leq 5.0$ and $n=3$. The optimal solution for this basin function is $(v_0,\ldots,v_{n-1})=0.0$.
% algorithm
The algorithm is an implementation of Differential Evolution with the DE/rand/1/bin configuration proposed by Storn and Price \cite{Storn1997}. \\ 
% NOTE: this newline is a hack for layout niceness

% the listing
\lstinputlisting[firstline=7,language=ruby,caption=Differential Evolution in Ruby, label=differential_evolution]{../src/algorithms/evolutionary/differential_evolution.rb}


% References: Deeper understanding
% The references element description includes a listing of both primary sources of information about the technique as well as useful introductory sources for novices to gain a deeper understanding of the theory and application of the technique. The description consists of hand-selected reference material including books, peer reviewed conference papers, journal articles, and potentially websites. A bullet-pointed structure is suggested.
\subsection{References}
% What are the primary sources for a technique?
% What are the suggested reference sources for learning more about a technique?

% 
% Primary Sources
% 
\subsubsection{Primary Sources}
% seminal
The Differential Evolution algorithm was presented by Storn and Price in a technical report that considered DE1 and DE2 variants of the approach applied to a suite of continuous function optimization problems \cite{Storn1995}. 
% early papers, maturation
An early paper by Storn applied the approach to the optimization of an IIR-filter (Infinite Impulse Response) \cite{Storn1996a}. A second early paper applied the approach to a second suite of benchmark problem instances, adopting the contemporary nomenclature for describing the approach, including the DE/rand/1/* and DE/best/2/* variations \cite{Storn1996b}.
% seminal
The early work including technical reports and conference papers by Storn and Price culminated in a seminal journal article \cite{Storn1997}.

% 
% Learn More
% 
\subsubsection{Learn More}
% historical reviews
A classical overview of Differential Evolution was presented by Price and Storn \cite{Price1997}, and terse introduction to the approach for function optimization is presented by Storn \cite{Storn1996}. A seminal extended description of the algorithm with sample applications was presented by Storn and Price as a book chapter \cite{Price1999}.
% books
Price, Storn, and Lampinen released a contemporary book dedicated to Differential Evolution including theory, benchmarks, sample code, and numerous application demonstrations \cite{Price2005}. Chakraborty also released a book considering extensions to address complexities such as rotation invariance and stopping criteria  \cite{Chakraborty2008}.


