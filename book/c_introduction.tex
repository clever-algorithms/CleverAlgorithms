% The Clever Algorithms Project: http://www.CleverAlgorithms.com
% (c) Copyright 2010 Jason Brownlee. Some Rights Reserved. 
% This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 2.5 Australia License.

% This is a chapter

% Argument and background information the user requires to read and understand the book
\chapter{Introduction}
\label{chap:intro}
% welcome
\emph{Welcome to Clever Algorithms!} This is a handbook of recipes for computational problem solving techniques from the fields of Computational Intelligence, Biologically Inspired Computation, and Metaheuristics. 
% book
This introduction chapter provides relevant background information on Artificial Intelligence and Algorithms, whereas the final chapter covers some advanced topics to consider once a number of algorithms have been mastered. The core of the book provides a large corpus of algorithm described in a complete and consistent manner. It has been designed as a reference text rather then being read cover-to-cover, where specific techniques are looked up and whole classes of approaches browsed. 

% they are for using
Clever Algorithms are interesting, practical, and fun to learn about and implement.
% briefly the audience
Research scientists may be interested in browsing algorithm inspirations in search of an interesting system or process analogues to investigate. Developers and software engineers may compare various problem solving algorithms and technique-specific guidelines. Practitioners, students, and interested amateurs may implement state-of-the-art algorithms to address business or scientific needs, or simply play with the fascinating systems they represent.
% parting tweet


% 
% What is AI
% 
\section{What is AI}
\label{intro:sec:what_is_ai}
% 
% Artificial Intelligence (based on copy from my thesis)
% 
\subsection{Artificial Intelligence}
\label{sec:artificial_intelligence}
The field of classical \emph{Artificial Intelligence} (AI) coalesced after World War II in the 1950s drawing on an understanding of the brain from neuroscience, the new mathematics of information theory, control theory referred to as cybernetics, and the dawn of the digital computer. AI is a cross-disciplinary field of research generally concerned with developing and investigating systems that operate or act intelligently. It is generally considered a discipline in the field of computer science given the strong focus on computation.

Russell and Norvig provide a perspective that defines Artificial Intelligence in four categories: (1) systems that think like humans, (2) systems that act like humans, (3) systems that think rationally, (4) systems that act rationally \cite{Russell2009}. In their definition, acting like a human suggests that a system can do some specific things humans can do, this includes fields such as the Turing test, natural language processing, automated reasoning, knowledge representation, machine learning, computer vision, and robotics. Thinking like a human suggests systems that model the cognitive information processing properties of humans, for example a general problem solver and systems that build internal models of their world. Thinking rationally suggests laws of rationalism and structured thought, such as syllogisms and formal logic. Finally, acting rationally suggests systems that do rational things such as expected utility maximization and rational agents. 

Luger and Stubblefield suggest that AI is a sub-field of computer science concerned with the automation of intelligence, and like other sub-fields of computer science has both theoretical concerns (\emph{how and why do the systems work?}) and application concerns (\emph{where and when can the systems be used?}) \cite{Luger1993}. They suggest a strong empirical focus to research, because although there may be a strong desire for mathematical analysis, the systems themselves defy analysis due to their complexity. The machines and software investigated in AI are not black boxes, rather analysis proceeds by observing the systems interactions with their environment, followed by an internal assessment of the system to relate its structure back to their behavior.

Artificial Intelligence is therefore concerned with investigating mechanisms that underlie intelligence and intelligence behavior. The traditional approach toward designing and investigating AI (the so-called `good old fashioned' AI) has been to employ a symbolic basis for these mechanisms. A newer approach historically referred to as scruffy artificial intelligence or or soft computing does not necessarily use a symbolic basis, instead patterning these mechanisms after biological or natural processes. This represents a modern paradigm shift in interest from symbolic knowledge representations, to inference strategies for adaptation and learning, and has been referred to as neat versus scruffy approaches to AI. The neat philosophy is concerned with formal symbolic models of intelligence that can explain \emph{why} they work, whereas the scruffy philosophy is concerned with intelligent strategies that explain \emph{how} they work \cite{Sloman1990}.

\subsubsection{Neat AI}
The traditional stream of AI involves a top down perspective of problem solving, generally involving symbolic representations and logic processes that most importantly can explain why they work. The successes of this prescriptive stream include a multitude of specialist approaches such as rule-based expert systems, automatic theorem provers, and operations research techniques that underly modern planning and scheduling software. Although traditional approaches have resulted in significant success they have their limits, most notably scalability. Increases in problem size result in an unmanageable increase in the complexity of such problems meaning that although traditional techniques can guarantee an optimal, precise, or true solution, the computational execution time or computing memory required can be fantastically unreasonable.

\subsubsection{Scruffy AI}
There have been a number of thrusts in the field of AI toward less crisp techniques that are able to locate approximate, imprecise, or partially-true solutions to problems with a reasonable cost of resources. Such approaches are typically \emph{descriptive} rather than \emph{prescriptive}, describing a process for achieving a solution (how), but not explaining why they work (like the neater approaches). 

Scruffy AI approaches are defined as relatively simple procedures that result in complex emergent and self-organizing behavior that can defy traditional reductionist analyses, the effects of which can be exploited for quickly locating approximate solutions to intractable problems. A common characteristic of such techniques is the incorporation of randomness in their processes resulting in robust probabilistic and stochastic decision making contrasted to the sometimes more fragile crisp approaches. Another important common attribute is the adoption of an inductive rather than deductive approach to problem solving, generalizing solutions or decisions from sets of specific observations made by the system.

% 
% Natural Computation - based on copy from my thesis
% 
\subsection{Natural Computation}
\label{sec:natural_computation}
An important perspective on scruffy Artificial Intelligence is the motivation and inspiration for the core information processing strategy of a given technique. Computers can only do what they are instructed, therefore a consideration is to distill information principles and strategies from other fields of study, such as the physical world and biology. The study of biologically motivated computation is called Biologically Inspired Computing \cite{Castro2005a}, and is one of three related fields of Natural Computing \cite{Forbes2000, Forbes2005, Paton1994}. 
% more
Natural Computing is an interdisciplinary field concerned with the relationship of computation and biology, which in addition to Biologically Inspired Computing is also comprised of Computationally Motivated Biology and Computing with Biology \cite{Paun2005, Marrow2000}.

\subsubsection{Biologically Inspired Computation}
Biologically Inspired Computation is computation inspired by biological metaphor, also referred to as \emph{Biomimicry}, and \emph{Biomemetics} in other engineering disciplines \cite{Castro2005, Benyus1998}. The intent of this field is to devise mathematical and engineering tools to generate solutions to computation problems. Biologically Inspired Computation fits into this category, as do other non-computational areas of problem solving not discussed. At its simplest, the field involves using procedures for finding solutions found in the biological environment for addressing computationally phrased problems.

\subsubsection{Computationally Motivated Biology}
Computationally Motivated Biology involves investigating biology with computers. The intent of this area is to use information sciences and simulation to model biological systems in digital computers with the aim to replicate and better understand behaviors in biological systems. The field facilitates the ability to better understand life-as-it-is and investigate life-as-it-could-be. Typically, work in this sub-field is not concerned with the construction of mathematical and engineering tools, rather it is focused on simulating natural phenomena. Common examples include Artificial Life, Fractal Geometry (L-systems, Iterative Function Systems, Particle Systems, Brownian motion), and Cellular Automata. A related field is that of Computational Biology generally concerned with modeling biological systems and the application of statistical methods such as in the sub-field of Bioinformatics.

\subsubsection{Computation with Biology}
Computation with Biology is the investigation of substrates other than silicon in which to implement computation \cite{Aaronson2005}. Common examples include molecular or DNA Computing and Quantum Computing.

% 
% Computational Intelligence - based on copy from my thesis
% 
\subsection{Computational Intelligence}
\label{sec:computationl_intelligence}
Computational Intelligence is a modern name for the sub-field of AI concerned with sub-symbolic (messy, scruffy, soft) techniques. Generally, Computational Intelligence describes techniques that focus on \emph{strategy} and \emph{outcome}. 
% examples
Computational Intelligence broadly covers sub-disciplines that focus on adaptive and intelligence systems, not limited to: evolutionary computation, Swarm Intelligence (Particle Swarm and Ant Colony Optimization), Fuzzy Systems, Artificial Immune Systems, and Artificial Neural Networks \cite{Engelbrecht2007, Pedrycz1997}. This section provides a brief summary of the each of the five primary areas of study.

\subsubsection{Evolutionary Computation} 
A paradigm that is concerned with the investigation of systems inspired by the neo-Darwinian theory of evolution by means of natural selection. Popular evolutionary algorithms include the Genetic Algorithm, Evolution Strategy, Genetic and Evolutionary Programming, and Differential Evolution \cite{Baeck2000, Baeck2000a}. The evolutionary process is considered an adaptive strategy and is typically applied to search and optimization domains \cite{Goldberg1989, Holland1975}.

\subsubsection{Swarm Intelligence} 
A paradigm that considers collective intelligence as a behavior that emerges through the interaction and cooperation of large numbers of lesser intelligent agents. The paradigm consists of two dominant sub-fields (1) Ant Colony Optimization that investigates probabilistic algorithms inspired by the stigmergy and foraging behavior of ants \cite{Bonabeau1999, Dorigo2004}, and (2) Particle Swarm Optimization that investigates probabilistic algorithms inspired by the flocking and foraging behavior of birds and fish \cite{Shi2001}. Like evolutionary computation, swarm intelligences are considered adaptive strategies and are typically applied to search and optimization domains.

\subsubsection{Artificial Neural Networks}
A paradigm that is concerned with the investigation of architectures and learning strategies inspired by the modeling of neurons in the brain \cite{Bishop1995}. Learning strategies are typically divided into supervised and unsupervised which manage environmental feedback in different ways. Neural network learning processes are considered adaptive learning and are typically applied to function approximation and pattern recognition domains.

\subsubsection{Fuzzy Intelligence}
A paradigm that is concerned with the investigation of fuzzy logic which is a form of logic that is not constrained to true and false like propositional logic, but rather functions which define approximate truth or degreeâ€™s of truth \cite{Zadeh1996}. Fuzzy logic and fuzzy systems are a logic system used as a reasoning strategy and are typically applied to expert system and control system domains.

\subsubsection{Artificial Immune Systems}
A collection of approaches inspired by the structure and function of the acquired immune system of vertebrates. Popular approaches include clonal selection, negative selection, dendritic cell algorithm, and immune network algorithms. The immune-inspired adaptive processes vary in strategy and show similarities to the fields evolutionary computation and artificial neural networks, and are typically used for optimization and pattern recognition domains \cite{Castro2002}.  

% 
% Metaheuristics
% 
\subsection{Metaheuristics}
\label{sec:metaheuristics}
Another popular and general name for the strategy-outcome perspective of scruffy AI is \emph{Metaheuristics}. 
% heuristics
A heuristic is an algorithm that locates `good enough' solutions to a problem without concern for whether the solution can be proven to be correct \cite{Michalewicz2004}. Heuristic methods trade off concerns such as precision, quality, and accuracy in favor of computational effort (space and time efficiency). Some examples of heuristic methods include enumerative and greedy search procedures.

% meta
Like heuristics, metaheuristic may be considered a general algorithmic framework that can be applied to different optimization problems with relative few modifications to make them adapted to a specific problem \cite{Glover2003, Talbi2009}. The difference is that Metaheuristics are intended to extend the capabilities of heuristics by combining one or more heuristic methods (referred to as procedures) using a higher-level strategy (hence `meta'). A procedure in a metaheuristic is considered black-box in that little (if any) prior knowledge is known about it by the meta-heuristic, and as such it may be replaced with a different procedure. Procedures may be as simple as a the manipulation of a representation, to as complex as another metaheuristic. Some examples of metaheuristics include iterated local search, tabu search, the genetic algorithm, ant colony optimization, and simulated annealing.

Blum and Roli outline nine properties of metaheuristics \cite{Blum2003}, as follows: 
\begin{itemize}
	\item Metaheuristics are strategies that ``guide'' the search process.
	\item The goal is to efficiently explore the search space in order to find (near-)optimal solutions.
	\item Techniques which constitute metaheuristic algorithms range from simple local search procedures to complex learning processes.
	\item Metaheuristic algorithms are approximate and usually non-deterministic.
	\item They may incorporate mechanisms to avoid getting trapped in confined areas of the search space.
	\item The basic concepts of metaheuristics permit an abstract level description.
	\item Metaheuristics are not problem-specific.
	\item Metaheuristics may make use of domain-specific knowledge in the form of heuristics that are controlled by the upper level strategy.
	\item Todays more advanced metaheuristics use search experience (embodied in some form of memory) to guide the search.
\end{itemize}

% hyper
Hyperheuristics are yet another extension that focuses on heuristics that modify their parameters (online or offline) to improve the efficacy of solution or efficiency of the computation. Hyperheuristics provide high-level strategies that may employ machine learning and adapt their search behavior by modifying the application of the sub-procedures or even which procedures are used (operating on the space of heuristics which in turn operate within the problem domain) \cite{Burke2003a, Burke2003}. 

% 
% Clever Algorithms
% 
\subsection{Clever Algorithms}
\label{sec:clever_algorithms}
% algorithm soures
The Clever Algorithms project is concerned with algorithms drawn from across many sub-fields of Artificial Intelligence not limited to the scruff fields of Biologically Inspired Computation, Computational Intelligence and Metaheuristics. 
% focus
The current set of algorithms selected to be described in the project may generally be referred to as `unconventional optimization algorithms' (for example, see \cite{Corne1999}), as optimization is the main form of computation provided by the listed approaches \cite{Brownlee2010b}. A technically more appropriate name for these approaches is Stochastic Global Optimization (for example, see \cite{Weise2007} and \cite{Luke2009}).

% the name
The term \emph{Clever Algorithms} is intended to unify a collection of interesting and useful computational tools under a consistent and accessible banner. An alternative name (\emph{Inspired Algorithms}) was considered, although ultimately rejected given that not all of the algorithms to be described in the project have an inspiration (specifically a biological or physical inspiration) for their computational strategy. The term `Clever Algorithms' was chosen for accessibility and not as a new branch of study (a branch that perhaps already has too many names). It is general enough that it may be used to describe any so-called `intelligent systems', and sufficiently underutilized (from a marketing perspective) that it may be specialized as needed, such as its current application to unconventional optimization algorithms. The generality also means that project may be extended into a series and cover model-generating algorithms such as fuzzy systems and artificial neural networks without ambiguity.

% furure
This gentle introduction to Artificial Intelligence was not exhaustive, focusing only on the duality of scruffy and neat approaches as a context for discussing the three areas of interest for the Clever Algorithms project. A useful extension to this work would be an explicit listing (annotated bibliography) of reference books and articles that may be used by interested readers to gain a deeper understanding of each of the fields introduced. Additional future efforts may consider the relationship of Statistical Machine Learning to Artificial Intelligence and the difference of the perspective on intelligent systems compared to those considered in this report, especially considering that there exists some overlap of approaches.

% 
%  Problems - based on copy from my thesis
% 
\section{Problems}
\label{sec:problems}
Algorithms from the fields of Computational Intelligence, Natural Computing, and Metaheuristics are applied to difficult problems, to which more traditional approaches may not be suited.
% problem types
Michalewicz and Fogel propose five reasons why problems may be difficult \cite{Michalewicz2004} (page 11):
\begin{itemize}
	\item The number of possible solutions in the search space is so large as to forbid an exhaustive search for the best answer.
	\item The problem is so complicated that just to facilitate any answer at all, we have to use such simplified models of the problem that any result is essentially useless.
	\item The evaluation function that describes the quality of any proposed solution is noisy or varies with time, thereby requiring not just a single solution but an entire series of solutions.
	\item The possible solutions are so heavily constrained that constructing even one feasible answer is difficult, let alone searching for an optimal solution.
	\item The person solving the problem is inadequately prepared or imagines some psychological barrier that prevents them from discovering a solution.
\end{itemize}

% classes
This section introduces two problem formalisms that embody many of the most difficult problems faced by Artificial and Computational Intelligence. They are: Function Optimization (in Section~\ref{subsec:function_optimization}) and Function Approximation (in Section~\ref{subsec:function_approximation}). Each class of problem is described in terms of its general properties, a formalism, and a set of specialized sub-problems. These problem classes provide a tangible framing of the algorithmic techniques drawn from the fields of Computational Intelligence, Natural Computing, and Metaheuristics.

% 
%  Function Optimization - based on copy from my thesis
%
\subsection{Function Optimization}
\label{subsec:function_optimization}
Real-world optimization problems and generalizations thereof can be drawn from most fields of science, engineering, and information technology (for a sample see \cite{Ali1997, Toern1999}). Importantly, optimization problems have had a long tradition in the fields of Artificial Intelligence in motivating basic research into new problem solving techniques, and for investigating and verifying systemic behavior against benchmark problem instances.

%
% Problem Definition
%
\subsubsection{Problem Description}
% definition
Mathematically, optimization is defined as the search for a combination of parameters commonly referred to as decision variables ($x = \left\{x_1, x_2, x_3, \ldots x_n\right\}$) which minimize or maximize some ordinal quantity ($c$) (typically a scalar  called a score or cost) assigned by an objective function or cost function ($f$), under a set of constraints ($g = \left\{g_1, g_2, g_3, \ldots g_n\right\}$). For example, a general minimization case would be as follows: $f(x\prime) \leq f(x), \forall x_i \in x$. Constraints may provide boundaries on decision variables (for example in a real-value hypercube $\Re^n$), or may generally define regions of feasibility and in-feasibility in the decision variable space. In applied mathematics the field may be referred to as Mathematical Programming. More generally the field may be referred to as Global or Function Optimization given the focus on the objective function (for more general information on optimization, see \cite{Horst2000}). 

%
% Sub-fields
%
\subsubsection{Sub-Fields of Study}
% general taxonomy
The study of optimization is comprised of many specialized sub-fields, generally based on an overlapping taxonomy that focuses on the principle concerns in the general formalism. 
% general fields
For example, with regard to the decision variables, one may consider univariate and multivariate optimization problems. The type of decision variables promotes the specialities for continuous, discrete, and permutations of variables. Dependencies between decision variables under a cost function define the fields of Linear Programming, Quadratic Programming, and Nonlinear Programming. A large class of optimization problems can be reduced to discrete sets and are considered in the field of Combinatorial Optimization, to which many theoretical properties are known, most importantly that many interesting and relevant problems cannot be solved by an approach with polynomial time complexity (so-called NP-complete, for example see \cite{Papadimitriou1998}).

% need for more complex models
The topography of the response surface for the decision variables under the cost function may be convex, which is an important class of functions to which many important theoretical findings have been made, not limited to the fact that location of the local optimal configuration also means the global optimal configuration of decisional variables has been located \cite{Boyd2004}. Many interesting and real-world optimization problems produce cost surfaces that are non-convex or so called multi-modal\footnote{Taken from statistics referring to the centers of mass in distributions, although in optimization it refers to `regions of interest' in the search space, in particular valleys in minimization, and peaks in maximization cost surfaces.} (rather than uni-modal) suggesting that there are multiple peaks and valleys. Further, many real-world optimization problems with continuous decision variables cannot be differentiated given their complexity or limited information availability meaning that derivative-based gradient decent methods that are well understood are not applicable, requiring the use of so-called `direct search' (sample or pattern-based) methods \cite{Lewis2000}. Real-world objective function evaluation may be noisy, discontinuous, dynamic, and the constraints of real-world problem solving may require a viable or approximate solution in limited time or resources, motivating the need for heuristic approaches.


% 
%  Function Approximation - based on copy from my thesis
%
\subsection{Function Approximation}
\label{subsec:function_approximation}
% relation to ai and ci
The phrasing of real-world problems in the Function Approximation formalism are among the most computationally difficult considered in the broader field of Artificial Intelligence for reasons including: incomplete information, high-dimensionality, noise in the sample observations, and non-linearities in the target function.
% this section
This section considers the Function Approximation Formalism and related specialization's as a general motivating problem to contrast and compare with Function Optimization.

%
% Problem Definition
%
\subsubsection{Problem Description}
% definition
Function Approximation is a problem of finding a function ($f$) that approximates a target function ($g$), where typically the approximated function is selected based on a sample of observations ($x$, also referred to as the training set) taken from the unknown target function.
% ML
In machine learning, the function approximation formalism is used to describe general problem types commonly referred to as pattern recognition, such as classification, clustering, and curve fitting (called a decision or discrimination function). Such general problem types are described in terms of approximating an unknown Probability Density Function (PDF), which underlies the relationships in the problem space, and is represented in the sample data. This `function approximation' perspective of such problems is commonly referred to as statistical machine learning and/or density estimation \cite{Fukunaga1990, Bishop1995}.

%
% Sub-Fields of Study
%
\subsubsection{Sub-Fields of Study}
% really hard
The function approximation formalism can be used to phrase some of the hardest problems faced by Computer Science, and Artificial Intelligence in particular such as natural language processing and computer vision. 
% general process
The general process focuses on (i) the collection and preparation of the observations from the target function, (ii) the selection and/or preparation of a model of the target function, and (ii) the application and ongoing refinement of the prepared model. 
% important problem types 
Some important problem-based sub-fields include: 
\begin{itemize}
	\item \emph{Feature Selection} where a feature is considered an aggregation of attributes, where only those features that have meaning in the context of the target function are necessary to the modeling process \cite{Kudo2000, Guyon2003}.
	\item \emph{Classification} where observations are inherently organized into labelled groups (classes) and a supervised process models an underlying discrimination function to classify unobserved samples.
	\item \emph{Clustering} where observations may be organized into inherent groups based on common features although the groups are unlabeled requiring a process to model an underlying discrimination function without corrective feedback.
	\item \emph{Curve or Surface Fitting} where a model is prepared that provides a `best-fit' (called a regression) for a set of observations that may be used for interpolation over known observations and extrapolation for observations outside what has been observed.
\end{itemize}

% optimisation
The field of Function Optimization is related to Function Approximation, as many-sub-problems of Function Approximation may be defined as optimization problems. As such, many of the technique paradigms used for function approximation are differentiated based on the representation used and/or the optimization process used to minimize error or maximize effectiveness on a given approximation problem. 
% problems
The difficulty of Function Approximation problems centre around (i) the nature of the unknown relationships between attributes and features, (ii) the number (dimensionality) of of attributes and features, and (iii) general concerns of noise in such relationships and the dynamic availability of samples from the target function.
% other problems
Additional difficulties include the incorporation of prior knowledge (such as imbalance in samples, incomplete information and the variable reliability of data), and problems of invariant features (such as transformation, translation, rotation, scaling and skewing of features).


% 
% Unconventional Optimization
% 
\section{Unconventional Optimization}
\label{sec:unconventional_optimization}
% context
This selection provides an overview of so-named unconventional optimization algorithms for the function optimization class of problem. These types of algorithms comprise the majority of approaches selected for description in the Clever Algorithms project drawn from the fields of Computational Intelligence, Natural Computation, and Metaheuristics \cite{Brownlee2010b}. 
% unconventional
These algorithms are referred to as `unconventional' to differentiate them from the more traditional approaches, not limited to mathematical optimization algorithms (such as Newton's method and Gradient descent that uses derivatives to locate a local minimum) and direct search methods (such as the Simplex method and the Nelder-Mead method that use a search pattern to locate optima).

% section
Unconventional optimization algorithms are designed for the more difficult problem instances, the attributes of which were introduced in Section~\ref{subsec:function_optimization}. This section introduces some common attributes of this class of algorithm including: black box methods (Section~\ref{subsec:black_box}), the no-free-lunch theorem (Section~\ref{subsec:nfl}), the broader field of stochastic optimization (Section~\ref{subsec:stochastic}), and general approach of inductive learning (Section~\ref{subsec:induction}).

% 
% Black Box Methods
% 
\subsection{Black Box Algorithms}
\label{subsec:black_box}
% overview
Black Box optimization algorithms are those that exploit little, if any, information from a problem domain in order to devise a solution. They are generalized problem solving procedures that may be applied to a range of problems with very little modification \cite{Droste2006}.

% more detail - use info if avaiable
Domain specific knowledge refers to making use of known relationships between solution representations and the objective cost function. Generally speaking, the less domain specific information incorporated into a technique, the more flexible the technique, although the less efficient it will be for a given problem. For example, `random search' is the most general black box approach and is also the most flexible requiring only the generation of random solutions for a given problem. Random search also has a worst case behavior that is worse than enumerating an entire search domain given the freedom it has to resample the domain. In practice, the more prior knowledge available about a problem, the more information that should be exploited by a technique in order to efficiently locate a solution for the problem, heuristically or otherwise. Black box methods are those methods suitable for those problems where little information from the problem domain is available to be used by a problem solving approach.  

% 
% No Free Lunch - based on copy from my thesis
% 
\subsection{No Free Lunch}
\label{subsec:nfl}
% intro
The \emph{No Free Lunch Theorem} of search and optimization by Wolpert and Macready proposes that all black box optimization algorithms are the same for searching for the extremum of a cost function when averaged over all possible functions \cite{Wolpert1997, Wolpert1995}. The theorem has caused a lot of pessimism and misunderstanding, particularly in relation to the evaluation and comparison of computational intelligence algorithms.

% overview
The implication of the theorem is that searching for the `best' general-purpose black box optimization algorithm is theoretically impossible, as no such procedure exists. The theory applies to stochastic and deterministic optimization algorithms as well as to algorithms that learn and adjust their search strategy over time. It is invariant to the performance measure used and the representation selected. Perhaps the catalyst for cynicism related to algorithm benchmarking is a comment accompanying the proof suggesting that: ``\ldots \emph{comparisons reporting the performance of a particular algorithm with a particular parameter setting on a few sample problems are of limited utility}'' \cite{Wolpert1997}.

% more
The theorem is an important contribution to computer science, although its implications are theoretical. The original paper was produced at a time when grandiose generalizations were being made as to algorithm, representation, or configuration superiority. The practical impact of the theory is to encourage practitioners to bound claims of applicability for optimization algorithms. Wolpert and Macready encouraged effort be put into devising practical problem classes and into the matching of suitable algorithms to problem classes. Further they compelled practitioners to exploit domain knowledge in optimization algorithm application, which is now an axiom in the field.

% 
% Randomness
% 
\subsection{Stochastic Optimization}
\label{subsec:stochastic}
% Stochastic
Stochastic optimization algorithms those that use randomness to elicit non-deterministic behaviors, contrasted to purely deterministic procedures. 
most algorithms from the fields of Computational Intelligence, Natural Computation, and Metaheuristics may be considered to belong to sub-fields of the field of stochastic optimization. Algorithms that exploit randomness, are not random in behavior. Rather, they sample a problem space in a biased manner, focusing on areas of interest and neglecting less interesting areas \cite{Spall2003}. 
% mcmc
A class of techniques that focus on the stochastic sampling of a domain are called Markov Chain Monte Carlo (MCMC) algorithms that provide good average performance, quickly, and generally offer a low chance of the worst case performance. Such approaches are suited to problems with many coupled degrees of freedom, for example large, high-dimensional spaces. MCMC approaches involve stochastically sampling from a target distribution function similar to Monte Carlo simulation methods using a process that resembles a biased Markov chain.

% Monte Carlo
Monte Carlo methods are used for selecting a statistical sample to approximate a given target probability density function and are traditionally used in statistical physics. Samples are drawn sequentially and the process may include criteria for rejecting samples and biasing the sampling locations within high-dimensional spaces. 
% Markov Chian
Markov Chain processes provide a probabilistic model for state transitions or moves within a discrete domain called a walk or a chain of steps. A Markov system is only dependent on the current position in the domain in order to probabilistically determine the next step in the walk. 

% mcmc
MCMC techniques combine these two approaches to solve integration and optimization problems in large dimensional spaces by generating samples while exploring the space using a Markov chain process, rather than sequentially or independently \cite{Andrieu2003}. The step generation is configured to bias sampling in more important regions of the domain. Three examples of MCMC techniques include the Metropolis-Hastings algorithm, Simulated annealing for global optimization, and the Gibbs sampler which are commonly employed in the fields of physics, chemistry, statistics, and economics. 

% 
% Induction
% 
\subsection{Inductive Learning}
\label{subsec:induction}
% adaptation
Many unconventional optimization algorithms employ a process that includes the iterative improvement of candidate solutions against an objective cost function. This process of adaptation is generally a method by which the process obtains characteristics that improve the system's (candidate solution) relative performance in an environment (cost function). This adaptive behavior is commonly achieved through a `selectionist process' of repetition of the steps: generation, test, and selection. The use of non-deterministic processes mean that the sampling of the domain (the generation step) is typically non-parametric, although guided by past experience. 

% inductive learning
The method of acquiring information is called inductive learning or learning from example, where the approach uses the implicit assumption that specific examples are representative of the broader information content of the environment, specifically with regard to anticipated need. Many unconventional optimization approaches maintain a single candidate solution, a population of samples, or a compression thereof that provides both an instantaneous representation of all of the information acquired by the process, and the basis for future learning. 

% k-bandit
This method of simultaneously acquiring and improving information from the domain and the optimization of decision making (where to direct future effort) is called the $k$-armed bandit (two-armed and multi-armed bandit) problem from the field of statistical decision making or game theory \cite{Robbins1952} (for a contemporary treatment see \cite{Bergemann2006}). This formalism considers the capability of a strategy to allocate available resources proportional to the payoff the strategy is expected to receive. The classic example is the 2-armed bandit problem used by Goldberg to describe the behavior of the genetic algorithm \cite{Goldberg1989}. The example involves an agent that learns which one of the two slot machines provides more return by pulling the handle of each (sampling the domain) and biasing future handle pulls proportional to the expected utility, based on the probabilistic experience with the past distribution of the payoff. This formalism may also be used to understand the properties of inductive learning demonstrated by the adaptive behavior of most unconventional optimization algorithms.

% +/-
The limited use of prior knowledge from the domain (black box) coupled with the stochastic sampling process mean that the adapted solutions are created without top-down insight or instruction can sometimes be interesting, innovative, and even competitive with decades of human expertise \cite{Koza2003}. The stochastic iterative process of generate and test can be computationally wasteful, potentially re-searching areas of the problem space already searched, and requiring many trials or samples in order to achieve a `good enough' solution.


% 
% Book Organization
% 
\section{Book Organization}
\label{intro:sec:organization}
% overview
The book is organized into three parts: \emph{Background} that provides a gentle introduction to the field of Artificial Intelligence and what constitutes a clever algorithm, \emph{Algorithms} that describes a large number of techniques in a complete and a consistent manner organized into a rough algorithm groups, and \emph{Extensions} that reviews more advanced topics suitable for when a number of algorithms have been mastered.

% 
% Background
% 
\subsection{Background}
Provide you with enough information to understand the presented algorithms.

% 
% Algorithms
%
\subsection{Algorithms}
% taxonomy
Algorithms are presented in six groups or kingdoms distilled from the broader fields of study each in their own chapter, as follows: stochastic, physical, evolutionary, probabilistic, swarm, and immune algorithms.  
% requirements
A given algorithm is more than just a procedure or code listing. Each approach is an island of research and the meta-information that define the context of a technique are just as important to understanding and application as abstract recipes and concrete implementations. A standardized algorithm description was adopted to provide a consistent presentation of algorithms with a mixture of softer narrative descriptions, programmatic descriptions both abstract and concrete, and most importantly useful sources for finding out more information about the technique.  

% template
The standardized algorithm description template covers the following subjects:
\begin{itemize}
	\item \emph{Name}: The algorithm name defines the canonical name used to refer to the technique, in addition to common aliases, abbreviations, and acronyms. The name is used in terms of the heading and sub-headings of an algorithm description.
	\item \emph{Taxonomy}: The algorithm taxonomy defines where a techniques fits into the field, both the specific subfields of Computational Intelligence and Biologically Inspired Computation as well as the broader field of Artificial Intelligence. The taxonomy also provides a context for determining the relationships between algorithms.
	\item \emph{Inspiration}: (optional) The inspiration describes the specific system or process that provoked the inception of the algorithm. The inspiring system may non-exclusively be natural, biological, physical, or social. The description of the inspiring system may include relevant domain specific theory, observation, nomenclature, and most important must include those salient attributes of the system that are somehow abstractly or conceptually manifest in the technique.
	\item \emph{Metaphor}: (optional) The metaphor is a description of the technique in the context of the inspiring system or a different suitable system. The features of the technique are made apparent through an analogous description of the features of the inspiring system. The explanation through analogy is not expected to be literal scientific truth, rather the method is used as an allegorical communication tool. The inspiring system is not explicitly described, this is the role of the `inspiration' element, which represents a loose dependency for this element.
	\item \emph{Strategy}: The strategy is an abstract description of the computational model. The strategy describes the information processing actions a technique shall take in order to achieve an objective. The strategy provides a logical separation between a computational realization (procedure) and a analogous system (metaphor). A given problem solving strategy may be realized as one of a number specific algorithms or problem solving systems.
	\item \emph{Procedure}: The algorithmic procedure summarizes the specifics of realizing a strategy as a systemized and parameterized computation. It outlines how the algorithm is organized in terms of the computation, data structures, and representations. 
	\item \emph{Heuristics}: The heuristics element describe the commonsense, best practice, and demonstrated rules for applying and configuring a parameterized algorithm. The heuristics relate to the technical details of the techniques procedure and data structures for general classes of application (neither specific implementations not specific problem instances).
	\item \emph{Tutorial}: The tutorial description provides a guide to realizing the technique using a programming language. The result of completing the tutorial is a minimal yet complete implementation of the technique applied to a problem, similar or the same to the source code description. The tutorial description provides explanations as to the design decisions and rationale for the way the technique is implemented.
	\item \emph{References}: The references element description includes a listing of both primary sources of information about the technique as well as useful introductory sources for novices to gain a deeper understanding of the theory and application of the technique. The description consists of hand-selected reference material including books, peer reviewed conference papers, journal articles, and potentially websites.
\end{itemize}

% sample code
Source code examples are included in the algorithm descriptions, and as such the Ruby Programming Language was selected for use throughout the book. Ruby was selected because it supports the procedural programming paradigm such that examples can be ported to object-oriented and other paradigms, it is interpreted meaning the code can be directly executed without an introduced compilation step, and it is free to download and use from the website \url{http://www.ruby-lang.org}. Additionally Ruby is concise, expressive, and supports meta-programming features that improve the readability of code examples.

% 
% Extensions
%
\subsection{Extensions}
Things to think about once you have mastered a number of a algorithms.



% 
% How to Read this Book
% 
\section{How to Read this Book}
\label{intro:sec:how_to_read}
Who is this book for and how should it be read?

this is not a book about ai or any realted fields. for that see some refs. 
for free books see another set of refs

\subsection{Research Scientists}
ways in which scientists may read this material

\subsection{Developers}
ways in which programmers and developers may read this material

\subsection{Students}
ways in which students may read this material

\subsection{Interested Amateurs}
ways in which amateurs may read this material


% 
% Further Reading
% 
\section{Further Reading}
\label{intro:sec:further_reading}

a listing of books and papers that will be useful for a reader to get more detail on topics covered in this chapter

% EOF
